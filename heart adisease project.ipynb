{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9319489b",
   "metadata": {},
   "source": [
    "# importing used libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06dc26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31171b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c21cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800af65f",
   "metadata": {},
   "source": [
    "# reading and exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df38b878",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('heart_2020_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ff2afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['HeartDisease'] == 'Yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae8621a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df.sample(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f90c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfed493a",
   "metadata": {},
   "outputs": [],
   "source": [
    "colmns=df1.columns\n",
    "colmns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc11c64",
   "metadata": {},
   "source": [
    "# Statistical Description of the Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf8708d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6835db",
   "metadata": {},
   "source": [
    "# data cleaning and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19acf412",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a8b693",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ecb5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bb9a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fb1dde",
   "metadata": {},
   "source": [
    "# encoding non numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1022ed78",
   "metadata": {},
   "outputs": [],
   "source": [
    "for colmn in colmns:\n",
    "       df1 = df1.replace({colmn: {'Yes': 1, \n",
    "                                'No': 0}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc6e686",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.replace({'Sex': {'Male': 1, \n",
    "                                'Female': 0}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d678002c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[['age', 'Last age']] = df1.AgeCategory.str.split(\"-\", expand = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137ea367",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.drop('Last age',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd125501",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.replace({'Diabetic': {'Yes (during pregnancy)': 1, \n",
    "                                'No, borderline diabetes': 0}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e05330",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.replace({'age': {'80 or older': 80}})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092b9bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['age']=df1['age'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbea6bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Race'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1f9b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.replace({'Race': {'White': 0, \n",
    "                                'Hispanic': 1,\n",
    "                               'Black':2,\n",
    "                                'Other':3, 'Asian':4, 'American Indian/Alaskan Native':5}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde46380",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.replace({'GenHealth': {'Poor': 0, \n",
    "                                'Fair': 1,\n",
    "                               'Good':2,\n",
    "                                'Very good':3, 'Excellent':4}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da70294",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a485bc76",
   "metadata": {},
   "source": [
    "# splitting the data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b470cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting correlation heatmap\n",
    "fig, ax = plt.subplots(figsize=(15,15))    \n",
    "dataplot = sns.heatmap(df1.corr(numeric_only =True), annot=True)\n",
    "  \n",
    "# displaying heatmap\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ce36eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df1.drop((['HeartDisease','AgeCategory','MentalHealth','Race','SleepTime']),axis=1)\n",
    "y = df1['HeartDisease']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87b247a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51adbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "colmns=X.columns\n",
    "colmns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608bc740",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize =(15,9))\n",
    "ax.patch.set_facecolor('#CAD5E0')\n",
    "fig.patch.set_facecolor('#CAD5E0')\n",
    "mpl.rcParams['font.family'] = 'TeX Gyre Heros'\n",
    "\n",
    "sns.boxplot(data = X, ax=ax, palette='husl', orient=\"h\", linewidth=4);\n",
    "\n",
    "# Colors\n",
    "for i,artist in enumerate(ax.artists):\n",
    "    col = artist.get_facecolor()\n",
    "    artist.set_edgecolor(col)\n",
    "    artist.set_facecolor('None')\n",
    "    for j in range(i*6,i*6+6):\n",
    "        line = ax.lines[j]\n",
    "        line.set_color(col)\n",
    "        line.set_mfc(col)\n",
    "        line.set_mec(col)\n",
    "\n",
    "# Remove ticks\n",
    "ax.xaxis.set_ticks_position('none')\n",
    "ax.yaxis.set_ticks_position('none')\n",
    "\n",
    "# Remove axes splines\n",
    "for i in ['top', 'bottom', 'left', 'right']:\n",
    "    ax.spines[i].set_visible(False)\n",
    "\n",
    "# Remove grid\n",
    "ax.grid(False)\n",
    "\n",
    "# Change color axis\n",
    "plt.xticks(fontsize=16);\n",
    "plt.yticks(fontsize=16);\n",
    "\n",
    "# Title\n",
    "ax.set_title('Outliers', fontsize=40, fontweight=\"bold\", pad=20);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11417b32",
   "metadata": {},
   "source": [
    "## Scaling Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3683d728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling features\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "for col in X :\n",
    "     X[col] = MinMaxScaler().fit_transform(X[[col]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25b5735",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreDF = pd.DataFrame(columns=['accuracy','f1','recall',\"precision\",\"Algorithm\",\"Balanced-Data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812cf893",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , X_test , y_train , y_test = train_test_split(X,y,train_size=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c38b70",
   "metadata": {},
   "source": [
    "# Split and generate balance test/train set using SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2d2644",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sm = SMOTE(random_state = 42\n",
    "           )\n",
    "X_trainnew, y_trainnew = sm.fit_resample(X_train, y_train.ravel())\n",
    "class_balance = pd.Series(y_trainnew).value_counts().plot.bar()\n",
    "class_balance.set_title(\"Outcome ytrain (SMOTE)\")\n",
    "pd.Series(y_trainnew).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce91da3",
   "metadata": {},
   "source": [
    "# model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d9d2e1",
   "metadata": {},
   "source": [
    "here we train the models with balnced and unbalanced data and before and after hyperparameter tuning to see the diffrence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28bd3c0",
   "metadata": {},
   "source": [
    "# LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22522b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "loger= LogisticRegression()\n",
    "loger.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503276cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "loger1= LogisticRegression()\n",
    "loger1.fit(X_trainnew,y_trainnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf205f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred0 = loger.predict(X_test)\n",
    "print('Accuracy score: ', round(accuracy_score(y_test, y_pred0), 4))\n",
    "print('F1 Score: ', round(f1_score(y_test, y_pred0), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8f650e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = loger1.predict(X_test)\n",
    "print('Accuracy score: ', round(accuracy_score(y_test, y_pred1), 4))\n",
    "print('F1 Score: ', round(f1_score(y_test, y_pred1), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e642bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    " \n",
    "print(classification_report(y_test, y_pred0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e41864",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the confusion matrix\n",
    "cf_matrix = confusion_matrix(y_test, y_pred1)\n",
    "#print(cf_matrix)\n",
    "sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, \n",
    "            fmt='.2%', cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c65094",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "# L1 regularized logistic regression\n",
    "lr_l1 = LogisticRegressionCV(Cs=10, cv=4, penalty='l1', solver='liblinear').fit(X_train, y_train)\n",
    "y_pred1 = lr_l1.predict(X_test)\n",
    "print('Accuracy score: ', round(accuracy_score(y_test, y_pred1), 4))\n",
    "print('F1 Score: ', round(f1_score(y_test, y_pred1), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16be5809",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "# L1 regularized logistic regression\n",
    "lr_l = LogisticRegressionCV(Cs=10, cv=4, penalty='l1', solver='liblinear').fit(X_trainnew, y_trainnew)\n",
    "y_pred00 = lr_l.predict(X_test)\n",
    "print('Accuracy score: ', round(accuracy_score(y_test, y_pred00), 4))\n",
    "print('F1 Score: ', round(f1_score(y_test, y_pred00), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498ee681",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the confusion matrix\n",
    "cf_matrix = confusion_matrix(y_test, y_pred1)\n",
    "#print(cf_matrix)\n",
    "sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, \n",
    "            fmt='.2%', cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564d2074",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    " \n",
    "print(classification_report(y_test, y_pred1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d949891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L2 regularized logistic regression\n",
    "lr_l2 = LogisticRegressionCV(Cs=10, cv=4, penalty='l2', solver='liblinear').fit(X_train, y_train)\n",
    "y_pred2 = lr_l2.predict(X_test)\n",
    "print('Accuracy score: ', round(accuracy_score(y_test, y_pred2), 4))\n",
    "print('F1 Score: ', round(f1_score(y_test, y_pred2), 4))\n",
    "score = cross_validate(lr_l2, X_train, y_train, cv=10,scoring=['accuracy','f1','recall','precision'])\n",
    "print(\"Test accuracy:{}\".format(score[\"test_accuracy\"].mean()))\n",
    "data =[score[\"test_accuracy\"].mean(), score[\"test_f1\"].mean(), score[\"test_recall\"].mean(),\n",
    "       score[\"test_precision\"].mean(),\"logistic regression\",\"No\"]\n",
    "scoreDF = scoreDF.append(pd.DataFrame([data], columns=scoreDF.columns), ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57366b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# L2 regularized logistic regression\n",
    "lr_l22 = LogisticRegressionCV(Cs=10, cv=4, penalty='l2', solver='liblinear').fit(X_trainnew, y_trainnew)\n",
    "y_pred3 = lr_l22.predict(X_test)\n",
    "print('Accuracy score: ', round(accuracy_score(y_test, y_pred3), 4))\n",
    "print('F1 Score: ', round(f1_score(y_test, y_pred3), 4))\n",
    "score = cross_validate(lr_l22,  X_trainnew, y_trainnew, cv=10,scoring=['accuracy','f1','recall','precision'])\n",
    "print(\"Test accuracy:{}\".format(score[\"test_accuracy\"].mean()))\n",
    "data =[score[\"test_accuracy\"].mean(), score[\"test_f1\"].mean(), score[\"test_recall\"].mean(),\n",
    "       score[\"test_precision\"].mean(),\"logistic regression\",\"yes\"]\n",
    "scoreDF = scoreDF.append(pd.DataFrame([data], columns=scoreDF.columns), ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e398b5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the confusion matrix\n",
    "cf_matrix = confusion_matrix(y_test, y_pred3)\n",
    "#print(cf_matrix)\n",
    "sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, \n",
    "            fmt='.2%', cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66028702",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc4e0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    " \n",
    "print(classification_report(y_test, y_pred2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3289d34",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27aba7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# First model\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn = knn.fit(X_train, y_train)\n",
    "y_pred4 = knn.predict(X_test)\n",
    "print('Accuracy score: ', round(accuracy_score(y_test, y_pred4), 4))\n",
    "print('F1 Score: ', round(f1_score(y_test, y_pred4), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458101ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    " \n",
    "print(classification_report(y_test, y_pred4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f670674",
   "metadata": {},
   "source": [
    "# hyperparameter tuning for KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dff177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_k = 20\n",
    "# f1_scores = list()\n",
    "# error_rates = list() # 1-accuracy\n",
    "# accuracy_scores = list()\n",
    "\n",
    "# for k in range(1, max_k+1):\n",
    "    \n",
    "#     knn = KNeighborsClassifier(n_neighbors=k)\n",
    "#     knn = knn.fit(X_trainnew, y_trainnew)\n",
    "    \n",
    "#     y_pred5 = knn.predict(X_test)\n",
    "#     f1 = f1_score(y_pred5, y_test)\n",
    "#     print(f1)\n",
    "#     f1_scores.append((k, round(f1_score(y_test, y_pred5), 4)))\n",
    "#     error = 1-round(accuracy_score(y_test, y_pred5), 4)\n",
    "#     print(error)\n",
    "#     error_rates.append((k, error))\n",
    "#     acc= round(accuracy_score(y_test, y_pred5), 4)\n",
    "#     accuracy_scores.append((k, acc))\n",
    "    \n",
    "# f1_results = pd.DataFrame(f1_scores, columns=['K', 'F1 Score'])\n",
    "# error_results = pd.DataFrame(error_rates, columns=['K', 'Error Rate'])\n",
    "# acc_results = pd.DataFrame(accuracy_scores, columns=['K', 'acc Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d874ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#acc_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623f620c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# mpl.rcParams['font.size'] = 12\n",
    "# sns.set_style(\"whitegrid\", {'grid.linestyle': '--'})  # set grid\n",
    "\n",
    "# fig, (ax_f1,ax_accuracy) = plt.subplots(1, 2, figsize=(20, 20))\n",
    "\n",
    "# fig.patch.set_facecolor('#F1F3F4')\n",
    "# ax_f1.patch.set_facecolor('#F1F3F4')\n",
    "# #ax_error.patch.set_facecolor('#F1F3F4')\n",
    "# ax_accuracy.patch.set_facecolor('#F1F3F4')\n",
    "\n",
    "# sns.lineplot(f1_results['F1 Score'], color = '#236AB9', ax=ax_f1)\n",
    "# #sns.lineplot(error_results['Error Rate'], color='#B85B14', ax=ax_error)\n",
    "# sns.lineplot(acc_results['acc Score'], color = '#236AB9', ax=ax_accuracy)\n",
    "\n",
    "# ax_f1.set_title('KNN F1 Score', color='#236AB9', fontsize= 25)\n",
    "# #ax_error.set_title('KNN Elbow Curve', color='#B85B14', fontsize= 25)\n",
    "# ax_accuracy.set_title('KNN accuracy Score', color='#236AB9', fontsize= 25)\n",
    "# # Set xticks range\n",
    "# ax_f1.set_xticks(range(1,20))\n",
    "# #ax_error.set_xticks(range(1,20))\n",
    "# ax_accuracy.set_xticks(range(1,20))\n",
    "\n",
    "# # Remove axes splines\n",
    "# for i in ['top', 'bottom', 'left', 'right']:\n",
    "#     ax_f1.spines[i].set_visible(False)\n",
    "\n",
    "# #for i in ['top', 'bottom', 'left', 'right']:\n",
    "#     #ax_error.spines[i].set_visible(False)\n",
    "    \n",
    "# for i in ['top', 'bottom', 'left', 'right']:\n",
    "#     ax_accuracy.spines[i].set_visible(False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf79ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=12)\n",
    "knn = knn.fit(X_train, y_train)\n",
    "y_pred6 = knn.predict(X_test)\n",
    "\n",
    "print('Accuracy score: ', round(accuracy_score(y_test, y_pred6), 4))\n",
    "print('F1 Score: ', round(f1_score(y_test, y_pred6), 4))\n",
    "score = cross_validate(knn, X_train, y_train, cv=10,scoring=['accuracy','f1','recall','precision'])\n",
    "print(\"Test accuracy:{}\".format(score[\"test_accuracy\"].mean()))\n",
    "data =[score[\"test_accuracy\"].mean(), score[\"test_f1\"].mean(), score[\"test_recall\"].mean(),\n",
    "       score[\"test_precision\"].mean(),\"KNeighbors Classifier\",\"No\"]\n",
    "scoreDF = scoreDF.append(pd.DataFrame([data], columns=scoreDF.columns), ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e43644",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn2 = KNeighborsClassifier(n_neighbors=8)\n",
    "knn2 = knn2.fit(X_trainnew, y_trainnew)\n",
    "y_pred7 = knn2.predict(X_test)\n",
    "\n",
    "print('Accuracy score: ', round(accuracy_score(y_test, y_pred7), 4))\n",
    "print('F1 Score: ', round(f1_score(y_test, y_pred7), 4))\n",
    "\n",
    "score = cross_validate(knn2,  X_trainnew, y_trainnew, cv=10,scoring=['accuracy','f1','recall','precision'])\n",
    "print(\"Test accuracy:{}\".format(score[\"test_accuracy\"].mean()))\n",
    "data =[score[\"test_accuracy\"].mean(), score[\"test_f1\"].mean(), score[\"test_recall\"].mean(),\n",
    "       score[\"test_precision\"].mean(),\"KNeighbors Classifier\",\"yes\"]\n",
    "scoreDF = scoreDF.append(pd.DataFrame([data], columns=scoreDF.columns), ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3377020b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the confusion matrix\n",
    "cf_matrix = confusion_matrix(y_test, y_pred7)\n",
    "#print(cf_matrix)\n",
    "sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, \n",
    "            fmt='.2%', cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8e2f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9252225",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    " \n",
    "print(classification_report(y_test, y_pred3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6dfc85",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28029b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt = dt.fit(X_train, y_train)\n",
    "y_pred8 = dt.predict(X_test)\n",
    "\n",
    "print('Accuracy score: ', round(accuracy_score(y_test, y_pred8), 4))\n",
    "print('F1 Score: ', round(f1_score(y_test, y_pred8), 4))\n",
    "\n",
    "score = cross_validate(dt, X_train, y_train, cv=10,scoring=['accuracy','f1','recall','precision'])\n",
    "print(\"Test accuracy:{}\".format(score[\"test_accuracy\"].mean()))\n",
    "data =[score[\"test_accuracy\"].mean(), score[\"test_f1\"].mean(), score[\"test_recall\"].mean(),\n",
    "       score[\"test_precision\"].mean(),\"Decision Tree Classifier\",\"No\"]\n",
    "scoreDF = scoreDF.append(pd.DataFrame([data], columns=scoreDF.columns), ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ce7e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt2 = DecisionTreeClassifier(random_state=42)\n",
    "dt2 = dt2.fit(X_trainnew, y_trainnew)\n",
    "y_pred9 = dt2.predict(X_test)\n",
    "\n",
    "print('Accuracy score: ', round(accuracy_score(y_test, y_pred9), 4))\n",
    "print('F1 Score: ', round(f1_score(y_test, y_pred9), 4))\n",
    "\n",
    "score = cross_validate(dt2, X_trainnew, y_trainnew, cv=10,scoring=['accuracy','f1','recall','precision'])\n",
    "print(\"Test accuracy:{}\".format(score[\"test_accuracy\"].mean()))\n",
    "data =[score[\"test_accuracy\"].mean(), score[\"test_f1\"].mean(), score[\"test_recall\"].mean(),\n",
    "       score[\"test_precision\"].mean(),\"Decision Tree Classifier\",\"yes\"]\n",
    "scoreDF = scoreDF.append(pd.DataFrame([data], columns=scoreDF.columns), ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80d681f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the confusion matrix\n",
    "cf_matrix = confusion_matrix(y_test, y_pred9)\n",
    "#print(cf_matrix)\n",
    "sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, \n",
    "            fmt='.2%', cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f1be01",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df9975c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    " \n",
    "print(classification_report(y_test, y_pred9))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4caaea4e",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e82c869",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# First model\n",
    "RF = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "                            \n",
    "RF = RF.fit(X_trainnew, y_trainnew)\n",
    "y_pred10 = RF.predict(X_test)\n",
    "\n",
    "print('Accuracy score: ', round(accuracy_score(y_test, y_pred10), 4))\n",
    "print('F1 Score: ', round(f1_score(y_test, y_pred10), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370bc224",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the confusion matrix\n",
    "cf_matrix = confusion_matrix(y_test, y_pred10)\n",
    "#print(cf_matrix)\n",
    "sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, \n",
    "            fmt='.2%', cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cec8fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    " \n",
    "print(classification_report(y_test, y_pred10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e6e95e",
   "metadata": {},
   "source": [
    "# hyperparameter tuning for RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c6a11c",
   "metadata": {},
   "outputs": [],
   "source": [
    " from sklearn.model_selection import GridSearchCV\n",
    "     from tqdm import tqdm\n",
    "\n",
    "n_estimators = [100, 150, 200]\n",
    "max_depth = [15, 20, 25]\n",
    "max_depth.append(None)\n",
    "max_features = ['auto', 'sqrt']\n",
    "min_samples_split = [5, 10, 15]\n",
    "min_samples_leaf = [1, 2]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "params = {'n_estimators': n_estimators, 'max_features': max_features,\n",
    "           'max_depth': max_depth, 'min_samples_split': min_samples_split,\n",
    "           'min_samples_leaf': min_samples_leaf, 'bootstrap': bootstrap,}\n",
    "\n",
    " RF = RandomForestClassifier(random_state=42,)\n",
    "\n",
    "grid_search = GridSearchCV(estimator = RF, \n",
    "                            param_grid = params,\n",
    "                            scoring = 'f1',\n",
    "                            cv = 5,\n",
    "                            verbose=3, \n",
    "                            n_jobs=-1)\n",
    "\n",
    " grid_search.fit(X_trainnew, y_trainnew)\n",
    "print(\"best score: \", grid_search.best_score_)\n",
    "print(\"best param: \", grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9d9800",
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_params = grid_search.best_params_\n",
    "RF1 = RandomForestClassifier(random_state=42, bootstrap=False, max_depth= 20, max_features= \"sqrt\", min_samples_leaf= 1, min_samples_split= 5, n_estimators=100)\n",
    "                            \n",
    "RF1 = RF1.fit(X_train, y_train)\n",
    "y_pred11 = RF1.predict(X_test)\n",
    "\n",
    "print('Accuracy score: ', round(accuracy_score(y_test, y_pred11), 4))\n",
    "print('F1 Score: ', round(f1_score(y_test, y_pred11), 4))\n",
    "\n",
    "score = cross_validate(RF1, X_train, y_train, cv=10,scoring=['accuracy','f1','recall','precision'])\n",
    "print(\"Test accuracy:{}\".format(score[\"test_accuracy\"].mean()))\n",
    "data =[score[\"test_accuracy\"].mean(), score[\"test_f1\"].mean(), score[\"test_recall\"].mean(),\n",
    "       score[\"test_precision\"].mean(),\"Random Forest Classifier1\",\"No\"]\n",
    "scoreDF = scoreDF.append(pd.DataFrame([data], columns=scoreDF.columns), ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cb8457",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF12 = RandomForestClassifier(random_state=42, bootstrap=False, max_depth= 20, max_features= \"sqrt\", min_samples_leaf= 1, min_samples_split= 5, n_estimators=100)\n",
    "scores=list()\n",
    "RF12 = RF12.fit(X_trainnew, y_trainnew)\n",
    "y_pred12= RF12.predict(X_test)\n",
    "\n",
    "print('Accuracy score: ', round(accuracy_score(y_test, y_pred12), 4))\n",
    "print('F1 Score: ', round(f1_score(y_test, y_pred12), 4))\n",
    "\n",
    "score = cross_validate(RF12, X_trainnew, y_trainnew, cv=10,scoring=['accuracy','f1','recall','precision'])\n",
    "print(\"Test accuracy:{}\".format(score[\"test_accuracy\"]))\n",
    "data =[score[\"test_accuracy\"].mean(), score[\"test_f1\"].mean(), score[\"test_recall\"].mean(),\n",
    "       score[\"test_precision\"].mean(),\"Random Forest Classifier1\",\"yes\"]\n",
    "scoreDF = scoreDF.append(pd.DataFrame([data], columns=scoreDF.columns), ignore_index=True)\n",
    "scores.append(score[\"test_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ede448",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the confusion matrix\n",
    "cf_matrix = confusion_matrix(y_test, y_pred12)\n",
    "#print(cf_matrix)\n",
    "sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, \n",
    "            fmt='.2%', cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92e5856",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cbd740",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    " \n",
    "print(classification_report(y_test, y_pred11))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55395778",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the confusion matrix\n",
    "cf_matrix = confusion_matrix(y_test, y_pred11)\n",
    "#print(cf_matrix)\n",
    "sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, \n",
    "            fmt='.2%', cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b800abd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    " \n",
    "print(classification_report(y_test, y_pred11))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de90fa5",
   "metadata": {},
   "source": [
    "# model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cd83b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we select the model base on the best results regarding accuracy, f1,precision,recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775274d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreDF = scoreDF[['Algorithm', 'Balanced-Data', 'accuracy', 'f1', 'precision','recall']]\n",
    "scoreDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3966e277",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Draw a nested barplot by species and sex\n",
    "ax = sns.catplot(\n",
    "    data=scoreDF, kind=\"bar\",\n",
    "    x=\"Algorithm\", y=\"f1\", hue=\"Balanced-Data\",\n",
    "     palette=\"dark\", alpha=.6, height=10\n",
    ")\n",
    "ax.despine(left=True)\n",
    "ax.set_axis_labels(\"Algorithms\", \"MEAN F1-Score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8372fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Draw a nested barplot by species and sex\n",
    "ax = sns.catplot(\n",
    "    data=scoreDF, kind=\"bar\",\n",
    "    x=\"Algorithm\", y=\"accuracy\", hue=\"Balanced-Data\",\n",
    "     palette=\"dark\", alpha=.6, height=10\n",
    ")\n",
    "ax.despine(left=True)\n",
    "ax.set_axis_labels(\"Algorithms\", \"MEAN accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d717e51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Draw a nested barplot by species and sex\n",
    "ax = sns.catplot(\n",
    "    data=scoreDF, kind=\"bar\",\n",
    "    x=\"Algorithm\", y=\"precision\", hue=\"Balanced-Data\",\n",
    "     palette=\"dark\", alpha=.6, height=10\n",
    ")\n",
    "ax.despine(left=True)\n",
    "ax.set_axis_labels(\"Algorithms\", \"MEAN precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1eadfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Draw a nested barplot by species and sex\n",
    "ax = sns.catplot(\n",
    "    data=scoreDF, kind=\"bar\",\n",
    "    x=\"Algorithm\", y=\"recall\", hue=\"Balanced-Data\",\n",
    "     palette=\"dark\", alpha=.6, height=10\n",
    ")\n",
    "ax.despine(left=True)\n",
    "ax.set_axis_labels(\"Algorithms\", \"MEAN recall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a7b6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name=X.columns\n",
    "col_name\n",
    "predict_data=np.array([])\n",
    "for i in range(14):\n",
    "    #inpt=input()\n",
    "    print('pleas enter your ',col_name[i],' here')\n",
    "    inpt=float(input())\n",
    "    predict_data=np.append(predict_data,inpt)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "predict_data_as_numpy_array= np.asarray(predict_data)\n",
    "\n",
    "\n",
    "predict_data_reshaped = predict_data_as_numpy_array.reshape(1,-1)\n",
    "\n",
    "prediction = RF12.predict(predict_data_reshaped)\n",
    "print(prediction)\n",
    "\n",
    "if (prediction[0]== 0):\n",
    "     print('The Person does not have a Heart Disease')\n",
    "else:\n",
    "      print('The Person has Heart Disease')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5586cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(RF12, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d595f016",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7816515a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
